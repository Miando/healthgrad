{"classifiers": ["Programming Language :: Python", "Programming Language :: Python :: 2.7", "Programming Language :: Python :: 3", "Programming Language :: Python :: 3.5", "Operating System :: OS Independent", "Environment :: Console", "Environment :: No Input/Output (Daemon)", "Topic :: Internet :: WWW/HTTP", "License :: OSI Approved :: BSD License"], "description_content_type": "UNKNOWN", "extensions": {"python.commands": {"wrap_console": {"scrapyrt": "scrapyrt.cmdline:execute"}}, "python.details": {"contacts": [{"email": "info@scrapinghub.com", "name": "Scrapinghub", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst"}, "project_urls": {"Home": "https://github.com/scrapinghub/scrapyrt"}}, "python.exports": {"console_scripts": {"scrapyrt": "scrapyrt.cmdline:execute"}}}, "extras": [], "generator": "bdist_wheel (0.30.0)", "license": "BSD", "metadata_version": "2.0", "name": "scrapyrt", "run_requires": [{"requires": ["Scrapy (>=1.0.0)", "Twisted (>=14.0.0)", "demjson", "six (>=1.5.2)"]}], "summary": "Put Scrapy spiders behind an HTTP API", "version": "0.10"}